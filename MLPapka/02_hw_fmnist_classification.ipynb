{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDsVMGiVgSq2"
   },
   "source": [
    "## Классификация FashionMNIST\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3isBRG6PgSq6"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "\n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "def get_accuracy(model, data_loader):\n",
    "    predicted_labels = []\n",
    "    real_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            y_predicted = model(batch[0].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "            real_labels.append(batch[1])\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    real_labels = torch.cat(real_labels)\n",
    "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
    "    return accuracy_score\n",
    "\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (pyproject.toml): started\n",
      "  Building wheel for wget (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9712 sha256=9696659e540da5b4519b1b9c534213833e3d4bc90cd4b31761ce2050b86782d0\n",
      "  Stored in directory: c:\\users\\babuleh\\appdata\\local\\pip\\cache\\wheels\\8a\\b8\\04\\0c88fb22489b0c049bee4e977c5689c7fe597d6c4b0e7d0b6a\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  286k    0  286k    0     0   349k      0 --:--:-- --:--:-- --:--:--  350k\n"
     ]
    }
   ],
   "source": [
    "!curl -L https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict.npy -o hw_overfitting_data_dict.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeA6Q5-CgSq7"
   },
   "source": [
    "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
    "\n",
    "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
    "\n",
    "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE_ID = 0  # change if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nPG1KbQAgl8b"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "device = (\n",
    "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    ")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "id": "aYcL28OsgSq8",
    "outputId": "93aafa07-fb56-43bd-f928-918f45fe30e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26.4M/26.4M [00:03<00:00, 8.78MB/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29.5k/29.5k [00:00<00:00, 801kB/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.42M/4.42M [00:00<00:00, 8.67MB/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5.15k/5.15k [00:00<00:00, 9.90MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 6')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_fmnist_data = FashionMNIST(\n",
    "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "test_fmnist_data = FashionMNIST(\n",
    "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f\"Image label: {_label}\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6jWRv1rgSq8"
   },
   "source": [
    "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
    "\n",
    "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(0) \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "BcyEFX-RgSq8"
   },
   "outputs": [],
   "source": [
    "# Creating model instance\n",
    "model_task_1 = MyModel()\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAoLV4dkoy5M"
   },
   "source": [
    "Не забудьте перенести модель на выбранный `device`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Xas9SIXDoxvZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/1875], Loss: 0.9718\n",
      "Epoch [1/5], Step [200/1875], Loss: 0.5846\n",
      "Epoch [1/5], Step [300/1875], Loss: 0.5148\n",
      "Epoch [1/5], Step [400/1875], Loss: 0.4658\n",
      "Epoch [1/5], Step [500/1875], Loss: 0.4195\n",
      "Epoch [1/5], Step [600/1875], Loss: 0.4160\n",
      "Epoch [1/5], Step [700/1875], Loss: 0.3859\n",
      "Epoch [1/5], Step [800/1875], Loss: 0.3896\n",
      "Epoch [1/5], Step [900/1875], Loss: 0.3793\n",
      "Epoch [1/5], Step [1000/1875], Loss: 0.3736\n",
      "Epoch [1/5], Step [1100/1875], Loss: 0.3458\n",
      "Epoch [1/5], Step [1200/1875], Loss: 0.3507\n",
      "Epoch [1/5], Step [1300/1875], Loss: 0.3411\n",
      "Epoch [1/5], Step [1400/1875], Loss: 0.3218\n",
      "Epoch [1/5], Step [1500/1875], Loss: 0.3464\n",
      "Epoch [1/5], Step [1600/1875], Loss: 0.3302\n",
      "Epoch [1/5], Step [1700/1875], Loss: 0.3099\n",
      "Epoch [1/5], Step [1800/1875], Loss: 0.3133\n",
      "Epoch [2/5], Step [100/1875], Loss: 0.2895\n",
      "Epoch [2/5], Step [200/1875], Loss: 0.2925\n",
      "Epoch [2/5], Step [300/1875], Loss: 0.2824\n",
      "Epoch [2/5], Step [400/1875], Loss: 0.2685\n",
      "Epoch [2/5], Step [500/1875], Loss: 0.2819\n",
      "Epoch [2/5], Step [600/1875], Loss: 0.2595\n",
      "Epoch [2/5], Step [700/1875], Loss: 0.2717\n",
      "Epoch [2/5], Step [800/1875], Loss: 0.2509\n",
      "Epoch [2/5], Step [900/1875], Loss: 0.2593\n",
      "Epoch [2/5], Step [1000/1875], Loss: 0.2723\n",
      "Epoch [2/5], Step [1100/1875], Loss: 0.2877\n",
      "Epoch [2/5], Step [1200/1875], Loss: 0.2425\n",
      "Epoch [2/5], Step [1300/1875], Loss: 0.2897\n",
      "Epoch [2/5], Step [1400/1875], Loss: 0.2606\n",
      "Epoch [2/5], Step [1500/1875], Loss: 0.2935\n",
      "Epoch [2/5], Step [1600/1875], Loss: 0.2530\n",
      "Epoch [2/5], Step [1700/1875], Loss: 0.2671\n",
      "Epoch [2/5], Step [1800/1875], Loss: 0.2449\n",
      "Epoch [3/5], Step [100/1875], Loss: 0.2278\n",
      "Epoch [3/5], Step [200/1875], Loss: 0.2307\n",
      "Epoch [3/5], Step [300/1875], Loss: 0.2420\n",
      "Epoch [3/5], Step [400/1875], Loss: 0.2269\n",
      "Epoch [3/5], Step [500/1875], Loss: 0.2235\n",
      "Epoch [3/5], Step [600/1875], Loss: 0.2225\n",
      "Epoch [3/5], Step [700/1875], Loss: 0.2238\n",
      "Epoch [3/5], Step [800/1875], Loss: 0.2178\n",
      "Epoch [3/5], Step [900/1875], Loss: 0.2303\n",
      "Epoch [3/5], Step [1000/1875], Loss: 0.2253\n",
      "Epoch [3/5], Step [1100/1875], Loss: 0.2155\n",
      "Epoch [3/5], Step [1200/1875], Loss: 0.2299\n",
      "Epoch [3/5], Step [1300/1875], Loss: 0.2322\n",
      "Epoch [3/5], Step [1400/1875], Loss: 0.1999\n",
      "Epoch [3/5], Step [1500/1875], Loss: 0.2287\n",
      "Epoch [3/5], Step [1600/1875], Loss: 0.2327\n",
      "Epoch [3/5], Step [1700/1875], Loss: 0.2004\n",
      "Epoch [3/5], Step [1800/1875], Loss: 0.2218\n",
      "Epoch [4/5], Step [100/1875], Loss: 0.1920\n",
      "Epoch [4/5], Step [200/1875], Loss: 0.1860\n",
      "Epoch [4/5], Step [300/1875], Loss: 0.1936\n",
      "Epoch [4/5], Step [400/1875], Loss: 0.1918\n",
      "Epoch [4/5], Step [500/1875], Loss: 0.1926\n",
      "Epoch [4/5], Step [600/1875], Loss: 0.1988\n",
      "Epoch [4/5], Step [700/1875], Loss: 0.2022\n",
      "Epoch [4/5], Step [800/1875], Loss: 0.1989\n",
      "Epoch [4/5], Step [900/1875], Loss: 0.1972\n",
      "Epoch [4/5], Step [1000/1875], Loss: 0.2006\n",
      "Epoch [4/5], Step [1100/1875], Loss: 0.1925\n",
      "Epoch [4/5], Step [1200/1875], Loss: 0.1835\n",
      "Epoch [4/5], Step [1300/1875], Loss: 0.1873\n",
      "Epoch [4/5], Step [1400/1875], Loss: 0.1929\n",
      "Epoch [4/5], Step [1500/1875], Loss: 0.2109\n",
      "Epoch [4/5], Step [1600/1875], Loss: 0.1876\n",
      "Epoch [4/5], Step [1700/1875], Loss: 0.1809\n",
      "Epoch [4/5], Step [1800/1875], Loss: 0.1860\n",
      "Epoch [5/5], Step [100/1875], Loss: 0.1659\n",
      "Epoch [5/5], Step [200/1875], Loss: 0.1615\n",
      "Epoch [5/5], Step [300/1875], Loss: 0.1552\n",
      "Epoch [5/5], Step [400/1875], Loss: 0.1564\n",
      "Epoch [5/5], Step [500/1875], Loss: 0.1507\n",
      "Epoch [5/5], Step [600/1875], Loss: 0.1547\n",
      "Epoch [5/5], Step [700/1875], Loss: 0.1572\n",
      "Epoch [5/5], Step [800/1875], Loss: 0.1581\n",
      "Epoch [5/5], Step [900/1875], Loss: 0.1791\n",
      "Epoch [5/5], Step [1000/1875], Loss: 0.1705\n",
      "Epoch [5/5], Step [1100/1875], Loss: 0.1713\n",
      "Epoch [5/5], Step [1200/1875], Loss: 0.1723\n",
      "Epoch [5/5], Step [1300/1875], Loss: 0.1696\n",
      "Epoch [5/5], Step [1400/1875], Loss: 0.1857\n",
      "Epoch [5/5], Step [1500/1875], Loss: 0.1863\n",
      "Epoch [5/5], Step [1600/1875], Loss: 0.1703\n",
      "Epoch [5/5], Step [1700/1875], Loss: 0.1489\n",
      "Epoch [5/5], Step [1800/1875], Loss: 0.1761\n",
      "Обучение завершено!\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model_task_1.parameters(), lr=0.001)\n",
    "\n",
    "model_task_1.train()\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model_task_1(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 100 == 99:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_data_loader)}], Loss: {running_loss / 100:.4f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Обучение завершено!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pLRWysggSq9"
   },
   "source": [
    "Локальные тесты для проверки вашей модели доступны ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qMQzo1ggSq9",
    "outputId": "c00008eb-ef88-4000-ce47-e8dedd26e061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].to(device)\n",
    "    y = random_batch[1].to(device)\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model_task_1(x)\n",
    "except Exception as e:\n",
    "    print(\"Something is wrong with the model\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
    "\n",
    "print(\"Everything seems fine!\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suRmIPwIgSq9"
   },
   "source": [
    "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJnU14bdnZa_"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zce7gt1gSq-"
   },
   "source": [
    "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usswrWYOgSq-"
   },
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Xua3TVZHgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.94728\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "l9KEKXBxgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.9128\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oyhmMobgSq_"
   },
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "OAIrURCEgSq_",
    "outputId": "7c983690-a92e-4693-89fb-7c86c002921a"
   },
   "outputs": [],
   "source": [
    "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
    "assert (\n",
    "    train_acc_task_1 >= 0.905\n",
    "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_fmnist_data_dict.npy\"\n",
    "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    \"train_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "    ),\n",
    "    \"test_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "    ),\n",
    "}\n",
    "\n",
    "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сдача задания\n",
    "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
    "    \n",
    "* `submission_dict_fmnist_task_1.json` в задачу Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtWnYAN_gSrA"
   },
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
